{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############变量名声明#####################################\n",
    "############## inputword，word 查询词(手动输入) ##############\n",
    "############## div_list_title list格式化后的标题数据源 #######\n",
    "############## div_list_text list格式化后的文本数据源 ########\n",
    "############## name_list_sub 删除em头标签 ####################\n",
    "############## name_list_text 删除em尾标签 ###################\n",
    "############## a_list 获取的链接 #############################\n",
    "############## name_list 获取的标题内容 ######################\n",
    "############## by zyb  date 2022/5/4 23:43 ###################\n",
    "############## 修改内容 完成了标题和链接的获取 ###############\n",
    "################### peace through power! :) ##################\n",
    "##############################################################\n",
    "############## by zyb  2022年5月5日01:45:04 ##################\n",
    "############## 修改内容 更新了url循环体,增加了百度指数爬取 ###\n",
    "##############################################################\n",
    "############## by zyb  2022年5月5日02:24:51 ##################\n",
    "############## 修改内容 增加了代理UA,将爬取过程写入循环体 ####\n",
    "##############################################################\n",
    "############## by zyb  2022年5月5日09:49:13 ##################\n",
    "#### 修改内容 增加了对百度指数的清洗和整理 准备写入数据库 ####\n",
    "## a_list和name_list不写入数据库 缘由为字符串过长 ############\n",
    "##############################################################\n",
    "############## by zyb  2022年5月6日09:59:31 ##################\n",
    "#### 修改内容 两个数据库分别连接成功 准备写入循环 ############\n",
    "##############################################################\n",
    "############## by zyb  2022年5月6日23:30:42 ##################\n",
    "#### 修改内容 mysql循环数据已经写入，准备优化分词 ############\n",
    "##############################################################\n",
    "############## by zyb  2022年5月10日10:58:14 #################\n",
    "#### 修改内容 mysql数据库已经写入完毕，准备与superset连接 ####\n",
    "##############################################################\n",
    "############## by zyb  2022年5月11日04:13:24 #################\n",
    "#### 链接完毕 version1版本（无gui）已完成 ####################\n",
    "##############################################################\n",
    "############## by zyb   2022年5月17日00:29:57 ################\n",
    "############## ARTI Programme 开始测试阶段    ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee964e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fake_useragent\n",
    "ua = fake_useragent.UserAgent()\n",
    "print(ua.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "from lxml import etree\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "inputword = input(\"请输入你要查询的内容：\")\n",
    "word = urllib.parse.quote(inputword)\n",
    "\n",
    "\n",
    "div_list_title = []\n",
    "div_list_text = []\n",
    "for i in range(0,110,10):\n",
    "    headers = {\"User-Agent\":ua.random}\n",
    "    url = requests.get('https://www.baidu.com/s?wd=%s&pn=%d&rsv_spt=1&rsv_iqid=0xda29fd77000003c6&issp=1&f=8&rsv_bp=1&rsv_idx=2&ie=utf-8&tn=baiduhome_pg&rsv_enter=1&rsv_dl=ib&rsv_sug3=21&rsv_sug1=6&rsv_sug7=101&rsv_sug2=0&rsv_btype=i&inputT=3202&rsv_sug4=4022'%(word,i), headers=headers,).content.decode(\"utf-8\")\n",
    "#     print(url)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(url, 'html.parser')\n",
    "    #爬取数据源，已经写入循环体内 2022年5月5日02:26:40\n",
    "    div_list_title_temp = soup.find_all('h3',class_ = 'c-title t t tts-title')\n",
    "    div_list_title.append(div_list_title_temp)\n",
    "    div_list_text_temp = soup.find_all('div',class_ = 'c-gap-top-small')\n",
    "    div_list_text.append(div_list_text_temp)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cce789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#格式化\n",
    "div_list_title = list(div_list_title)\n",
    "div_list_text = list(div_list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初步清理\n",
    "import re\n",
    "a_list = re.findall('href=\"(.*?)\"',str(div_list_title),re.S)\n",
    "name_list = re.findall('\"_blank\">(.*?)</a>',str(div_list_title),re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8846a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#删除多余数据,鉴于写这个代码的人是个懒狗，不知道怎么删除一对标签，于是采取此下策\n",
    "name_list_sub = str(name_list).replace('<em>', '')\n",
    "name_list_text = str(name_list_sub).replace('</em>', '')\n",
    "name_list_sub_list = []\n",
    "name_list_text_list = []\n",
    "name_list_sub_list = name_list_sub.split(\",\")\n",
    "name_list_text_list = name_list_text.split(\",\")\n",
    "name_list_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f7a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_list#链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d90ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# name_list_text#标题\n",
    "print(len(name_list_sub_list))\n",
    "print(len(name_list_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2abf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "###百度指数获取，为可视化做数据铺垫########\n",
    "#2022/5/5 百度指数并没有什么大用，转移思路，改变为爬取对这个词的每日搜索次数\n",
    "#真香.jpg，用了一点“非正常手段\"（写不出来，摆了）\n",
    "#https://github.com/longxiaofei/spider-BaiduIndex\n",
    "#pip install --upgrade qdata\n",
    "#下方为调用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96265557",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from qdata.baidu_index import (\n",
    "    get_feed_index,\n",
    "    get_news_index,\n",
    "    get_search_index,\n",
    "    get_live_search_index\n",
    ")\n",
    "\n",
    "keywords_list = [[inputword]]\n",
    "cookies = \"\"\"BIDUPSID=4A8B4531C9D280A3E77F2008AD412BA2; PSTM=1650093892; BDUSS=E1YWS1NSW9MS3hpazUzcExOZ1ZnbU91Q1JUQ0FYbWFxdVZldH5qYW1CVTlMcHBpRVFBQUFBJCQAAAAAAAAAAAEAAAAOrMxhd2luZHl6eWIxMjMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2hcmI9oXJiS; BDUSS_BFESS=E1YWS1NSW9MS3hpazUzcExOZ1ZnbU91Q1JUQ0FYbWFxdVZldH5qYW1CVTlMcHBpRVFBQUFBJCQAAAAAAAAAAAEAAAAOrMxhd2luZHl6eWIxMjMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2hcmI9oXJiS; Hm_up_d101ea4d2a5c67dab98251f0b5de24dc={\"uid_\":{\"value\":\"1640803342\",\"scope\":1}}; BAIDUID=4A8B4531C9D280A3E77F2008AD412BA2:SL=0:NR=10:FG=1; BDSFRCVID_BFESS=DzIOJeCT5G3oo_TDtiVF-GtYo7VXzVJTTPjcTR5qJ04BtyCVNwZ1EG0PtOg3cu-bwBlLogKK0mOTH6KF_2uxOjjg8UtVJeC6EG0Ptf8g0M5; H_BDCLCKID_SF_BFESS=tR3-sJoq2RbhKROvhjR_Dx_gyxoObtRxtNrEKxjgbnIhV451hl3_BnFB5RbHLU3k-eTTQhQRbxJ_HRo-yqjkbfJBQttjQn3et4jbK4KE3lnMeb7TyU42hf47yaji0q4Hb6b9BJcjfU5MSlcNLTjpQT8r5MDOK5OuJRLDoKPhJI_WbnKk-4QEbbQH-UnLqMoObmOZ0l8KtD-2eMoE-UOMMjL05fvXQPCOKKOg0PQmWIQHDn7_KTbJ-T-XXPrUyhOlWar4KKJxW-PWeIJo5Dc6DCuYhUJiB5OLBan7Lj6IXKohJh7FM4tW3J0ZyxomtfQxtNRJ0DnjtnLhbCDRe5LMD6vMbeTa54cbb4o2WbCQQqIM8pcNLTDK2MuWQqQX0n30KRvtWnrxaJ5Gfx3PjqO1j4_eXa5pWU6Ot2oQ5hTpLIKaSh5jDh3vb6ksD-RteltHHmry0hvctn6cShnCqfjrDRLbXU6BK5vPbNcZ0l8K3l02V-bIe-t2b6QhDHR02t3-MPoa3RTeb6rjDnCrXMvPXUI82h5y05OQ56RHKPbVXKOhDbrMh4n23nk4jJORXRj4BNRhBRjValb4fj6Ky4oTjxL1Db3Jb5_L5gTtsl5dbnboepvoD-cc3MvByPjdJJQOBKQB0KnGbUQkeq8CQft20b0EeMtjW6LEtb4toCtbtD83fP36q45HMt00qxby26nRMe59aJ5nQI5nhn7vBpOU5-FZQmcx-pcyJacvXfQFQUbmjRO206oay6O3LlO83h5wbaLDKl0MLPbceIOn5DcD5UDjXMnMBMPjamOnaIQc3fAKftnOM46JehL3346-35543bRTLnLy5KJYMDcnK4-XD633jGjP; H_PS_PSSID=36427_31660_35910_36165_34584_35978_36055_26350_36314; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; PSINO=1; BAIDUID_BFESS=433090267ACE37EE3CD2AA9018802CBB:FG=1; BA_HECTOR=8g008l2h20ak208kuj1h84vdi0r; Hm_lvt_d101ea4d2a5c67dab98251f0b5de24dc=1652283925,1652440206,1652534964,1652719177; Hm_lpvt_d101ea4d2a5c67dab98251f0b5de24dc=1652719178; ab_sr=1.0.1_NGJmNDNhZDc0YTZjMTE0Yjg5MWMxYTcyNWU2YmY0NDgxNzU2MjI5MmYwNjFlY2VkYTM0NzE3MDkzY2Y3MmJiNzI1ODI2MDM0YjliMmRiNGFjNGEyYTYzN2IwNzVjNDEwZmUzZTc0YjJlYTFiZWIyODU5ODljNTQ4NDc2MDZmYzBiMTRmMjAzMmEyYjBiOWY2MjkzMzQxZjY1NjUxNWYyMQ==; __yjs_st=2_MTY4YmIwMTIyNmViMWQzODY5YmViNGQzNGMyYjM5OWIwMGJkMTEyODgzNDUzZTU0MzBjZDhhMDVjZDQzNDQyMTQ3NTFkZmUxNTQ3Y2FlODNhZmY5YTU1NGFmNGFmNmJhZjBmZjliNDljOThjNGVmNWY2ODU1MWUyMTUyYmRkNzY3ZTU5NGIxZDY3NDYyNTQzN2FhMDNjYTUyYjNmYTY3NWFlNTNhMDQxOGRjMmViZjIxZjEwMjI0MTZlOWEzNDRiXzdfMWI2NDI3ZDE=; bdindexid=16tbs2cct441e8h24nutlqu512; RT=\"z=1&dm=baidu.com&si=7lzqjd7v485&ss=l38ybqko&sl=2&tt=175&bcn=https://fclog.baidu.com/log/weirwood?type=perf&ld=28c&ul=8au\"\"\"\n",
    "index_total = []\n",
    "# print(type(index_total))\n",
    "def test_get_feed_index():\n",
    "    \"\"\"获取资讯指数\"\"\"\n",
    "    for index in get_feed_index(\n",
    "        keywords_list=keywords_list,\n",
    "        start_date='2018-01-01',\n",
    "        end_date='2019-05-01',\n",
    "        cookies=cookies\n",
    "    ):\n",
    "        print(index)\n",
    "\n",
    "\n",
    "def test_get_news_index():\n",
    "    \"\"\"获取媒体指数\"\"\"\n",
    "    for index in get_news_index(\n",
    "        keywords_list=keywords_list,\n",
    "        start_date='2018-01-01',\n",
    "        end_date='2019-05-01',\n",
    "        cookies=cookies\n",
    "    ):\n",
    "        print(index)\n",
    "\n",
    "\n",
    "def test_get_search_index():\n",
    "    \"\"\"获取搜索指数\"\"\"\n",
    "    for index in get_search_index(\n",
    "        keywords_list=keywords_list,\n",
    "        start_date='2018-01-01',\n",
    "        end_date='2019-05-01',\n",
    "        cookies=cookies\n",
    "    ):\n",
    "        print(index)\n",
    "\n",
    "\n",
    "def test_get_live_search_index():\n",
    "    \"\"\"获取搜索指数实时数据\"\"\"\n",
    "    \n",
    "    global index_total\n",
    "    \n",
    "#     for index in get_live_search_index(\n",
    "#         keywords_list=keywords_list,\n",
    "#         cookies=cookies,\n",
    "#         area=0\n",
    "#     ):\n",
    "# #         print(index)\n",
    "\n",
    "    for index in get_live_search_index(\n",
    "        keywords_list=keywords_list,\n",
    "        cookies=cookies,\n",
    "        area=911\n",
    "    ):\n",
    "#         index = list(index.items())\n",
    "#         print(type(index))\n",
    "       index_total.append(index)\n",
    "       print(index)\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # test_get_feed_index()\n",
    "    # test_get_news_index()\n",
    "    # test_get_search_index()\n",
    "    test_get_live_search_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历keys\n",
    "# print(index_total)\n",
    "index_total_keys= []\n",
    "# print(type(index_total))\n",
    "# keys = list(dic.keys())\n",
    "for i in range(len(index_total)):\n",
    "    for key in index_total[i]:\n",
    "        index_total_keys.append(key)\n",
    "print(index_total_keys)    \n",
    "# print(index_total[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历values\n",
    "#写入数据库未完成 2022年5月5日09:39:20\n",
    "index_total_values= []\n",
    "for i in range(len(index_total)):\n",
    "    for values in index_total[i].values():\n",
    "            index_total_values.append(values)\n",
    "print(index_total_values)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656df066",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(index_total_values))    \n",
    "print(len(index_total_keys))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6084747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#连数据库 写数据\n",
    "#s2022年5月5日07:36:37\n",
    "#写入数据库未完成 2022年5月5日09:39:20\n",
    "#此部分已废除，过于耗时\n",
    "# import mysql.connector\n",
    "# dbconfig = {\n",
    "#     'host': '127.0.0.1',\n",
    "#     'user': 'root',\n",
    "#     'password': '000000',\n",
    "#     'database': 'seodb',\n",
    "# }\n",
    "# conn = mysql.connector.connect(**dbconfig)\n",
    "# cursor = conn.cursor(prepared=True)\n",
    "# _SQL = \"\"\"INSERT INTO `live_search` (`name`, `index`, `datetime`, `values`) VALUES (%s, %s, %s, %s)\"\"\"\n",
    "# for i in range(len(index_total_keys)):\n",
    "#     for j in range(2,len(index_total_values),4):\n",
    "#         name = inputword \n",
    "#         str1 = index_total_values[j]\n",
    "#         datetime = str1\n",
    "#         for k in range(1,len(index_total_values),4):\n",
    "#             index = str(index_total_values[k])\n",
    "#             for u in range(3,len(index_total_values),4):\n",
    "#                 values = int(index_total_values[u])\n",
    "                \n",
    "#                 cursor.execute(_SQL,(name,index,datetime,values))\n",
    "#                 conn.commit()\n",
    "#     date = str(index_total_values[i])\n",
    "\n",
    "# type = \"type\"\n",
    "\n",
    "\n",
    "#数据库连接成功\n",
    "#时间已经放置 2022年5月9日16:09:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b325539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#连数据库 写数据\n",
    "#s2022年5月5日07:36:37\n",
    "#写入数据库未完成 2022年5月5日09:39:20\n",
    "#数据库连接成功\n",
    "#时间已经放置 2022年5月9日16:09:45\n",
    "#插完了.jpg\n",
    "#暴力一时爽，耗时火葬场.jpg\n",
    "#by zyb 2022年5月10日10:45:12\n",
    "import mysql.connector\n",
    "dbconfig = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': '000000',\n",
    "    'database': 'seodb',\n",
    "}\n",
    "conn = mysql.connector.connect(**dbconfig)\n",
    "cursor = conn.cursor(prepared=True)\n",
    "\n",
    "_SQL2= \"\"\"INSERT INTO `live_search` (`name`, `datetime`,`index`,`values`) VALUES (%s, %s, %s, %s)\"\"\"\n",
    "\n",
    "for j in range(2,len(index_total_values),4):\n",
    "    name = inputword \n",
    "    str1 = index_total_values[j]\n",
    "    index = str(index_total_values[j-1])\n",
    "    values = int(index_total_values[j+1])\n",
    "    datetime = str1\n",
    "    \n",
    "    cursor.execute(_SQL2,(name,datetime,index,values))\n",
    "    conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36037ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430a022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#问答模式 2022年5月17日01:54:35\n",
    "cont_name_list = []\n",
    "for i in range(len(a_list)):\n",
    "    try:\n",
    "        address = a_list[i]\n",
    "        headers = {\n",
    "            \"User-Agent\":ua.random\n",
    "        }\n",
    "        cont_child = requests.get(address, headers=headers).content\n",
    "#         cont_child_list = etree.HTML(cont_child)\n",
    "        cont_child_list = BeautifulSoup(cont_child,\"html.parser\")\n",
    "        for j in cont_child_list.find_all('p'):\n",
    "            print(cont_child_list.get_text().replace('\\n', '').replace('\\xa0', ''))\n",
    "            cont_name_list.append(cont_child_list.get_text().replace('\\n', '').replace('\\xa0', ''))\n",
    "#         cont_name_list.append(cont_child_list.xpath('//p/text()'))\n",
    "#         print(cont_name_list)\n",
    "    except :\n",
    "        pass\n",
    "#         print(\"未知异常\")\n",
    "# print(cont_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf12ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#清理重复数据集\n",
    "# s=[x.strip() for x in cont_name_list]\n",
    "cont_name_list=list(set(cont_name_list))\n",
    "print(cont_name_list) \n",
    "print(len(cont_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d332181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test example\n",
    "#没时间调优了 先放着 2022年5月12日08:36:15\n",
    "#计划项目变更 ARTI PROGRAMME计划启动。2022年5月17日02:10:39\n",
    "# import jieba\n",
    "# from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "# from sklearn.cluster import KMeans\n",
    "# def jieba_tokenize(text):\n",
    "#     return jieba.lcut(text)\n",
    "# tfidf_vectorizer = TfidfVectorizer(tokenizer=jieba_tokenize, lowercase=False)\n",
    "# #需要进行聚类的文本集\n",
    "# # text_list = [\"今天天气真好啊啊啊啊\", \"我早上8点起床的\", \\\n",
    "# # \"我今天拿到了Google的Offer\", \"清华大学在自然语言处理方面真厉害\"]\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(cont_name_list)\n",
    "# num_clusters = 1\n",
    "# km_cluster = KMeans(n_clusters=num_clusters, max_iter=400, n_init=1,init='k-means++')\n",
    "\n",
    "# #返回各自文本的所被分配到的类索引\n",
    "\n",
    "# result = km_cluster.fit_predict(tfidf_matrix)\n",
    "# # if result = result:\n",
    "    \n",
    "# print(\"Predicting result: \", result)\n",
    "# print(len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee232a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 10:08:52 2017\n",
    "\n",
    "@author: li-pc\n",
    "\"\"\"\n",
    "#计划项目变更 ARTI PROGRAMME计划启动。2022年5月17日02:10:39\n",
    "import jieba \n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "def jieba_tokenize(text):\n",
    "    return jieba.lcut(text) \n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=jieba_tokenize, lowercase=False)\n",
    "print(\"ok3\")\n",
    " #需要进行聚类的文本集\n",
    "print(\"ok1\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(cont_name_list)\n",
    "num_clusters = 2\n",
    "km_cluster = KMeans(n_clusters=num_clusters, max_iter=300, n_init=1,init='k-means++')\n",
    "print(\"ok2\")\n",
    "#返回各自文本的所被分配到的类索引\n",
    "result = km_cluster.fit_predict(tfidf_matrix)\n",
    "print(\"Predicting result: \"), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "type(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edcb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "#     print(i)\n",
    "    if result[i] == 1:\n",
    "        pprint.pprint(cont_name_list[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "boot_list = []\n",
    "oob_list = []\n",
    "for i in range(len(cont_name_list)):\n",
    "    for j in range(len(cont_name_list[i])):\n",
    "        try:\n",
    "            boot = resample(cont_name_list[j], replace=True, n_samples=1, random_state=j)\n",
    "            boot_list.append(boot)\n",
    "    #         print('Bootstrap Sample: %s' % boot)\n",
    "\n",
    "            # 袋外观察\n",
    "            oob = [x for x in cont_name_list[j] if x not in boot]\n",
    "            oob_list.append(oob)\n",
    "    #         print('OOB Sample: %s' % oob)\n",
    "    #         print(len(oob))\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "print(len(boot_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5f740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15dab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60fdd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "boot_list = []\n",
    "oob_list = []\n",
    "\n",
    "try:\n",
    "    boot = resample(cont_name_list, replace=True, n_samples=1, random_state=j)\n",
    "    boot_list.append(boot)\n",
    "    #         print('Bootstrap Sample: %s' % boot)\n",
    "\n",
    "            # 袋外观察\n",
    "    oob = [x for x in cont_name_list if x not in boot]\n",
    "    oob_list.append(oob)\n",
    "#     print('OOB Sample: %s' % oob)\n",
    "    print(len(oob))\n",
    "except :\n",
    "    pass\n",
    "\n",
    "print(len(boot_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54309f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boot_list)\n",
    "import pyttsx3\n",
    "pyttsx3.speak(boot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd33b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(oob_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(oob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len((name_list_text_list)))\n",
    "print(len(a_list))\n",
    "correct =  len(name_list_text_list)-len(a_list)\n",
    "print(type(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbfa436",
   "metadata": {},
   "source": [
    "'''\n",
    "tokenizer: 指定分词函数\n",
    "lowercase: 在分词之前将所有的文本转换成小写，因为涉及到中文文本处理，\n",
    "所以最好是False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace821ad",
   "metadata": {},
   "source": [
    "n_clusters: 指定K的值\n",
    "max_iter: 对于单次初始值计算的最大迭代次数\n",
    "n_init: 重新选择初始值的次数\n",
    "init: 制定初始值选择的算法\n",
    "n_jobs: 进程个数，为-1的时候是指默认跑满CPU\n",
    "注意，这个对于单个初始值的计算始终只会使用单进程计算，\n",
    "并行计算只是针对与不同初始值的计算。比如n_init=10，n_jobs=40, \n",
    "服务器上面有20个CPU可以开40个进程，最终只会开10个进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### finally.........the end ###############\n",
    "\n",
    "#测试neo4j连接\n",
    "#词频分析(x)\n",
    "#放置a_list和name_list_text_list\n",
    "from py2neo import Graph, Node, Relationship\n",
    "\n",
    "# Graph()中第一个为local host链接，auth为认证，包含 username 和 password\n",
    "gragh= Graph('http://localhost:7474', auth = ('neo4j', '000000'))\n",
    "#label\n",
    "leader = Node(inputword,name=inputword)\n",
    "for i in range(len(name_list_text_list)):\n",
    "    a = Node(inputword, name=name_list_text_list[i],link = a_list[i-correct])  # Node(label, name)\n",
    "#     b = Node(inputword, name=name_list_text_list[1])\n",
    "    al = Relationship(a, \"friend\", leader)\n",
    "    gragh.create(al)  # 创建节点和关系\n",
    "for j in range(len(boot_list)):\n",
    "    c = Node(inputword, name=boot_list[j])\n",
    "    ca = Relationship(c, \"friend\", a)\n",
    "    gragh.create(ca)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf5083",
   "metadata": {},
   "source": [
    "#第一层节点\n",
    "a_list\n",
    "name_list_text_list\n",
    "#第二层节点,一层节点与主节点均为friend关系，二层节点boot_list与name_list_text_list为friend关系\n",
    "boot_list\n",
    "oob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc65f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# 具体情景规定了到底何为情感。\n",
    "# 若拥有定义情景的能力，情感要素不过手中粘土，可以随意摆弄。\n",
    "#如今 我们将亲自定义成功。\n",
    "#######\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
